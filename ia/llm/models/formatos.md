Original Llama2 code uses the GPTQ format for the weights. This format is a quantized version of the GPT-2 model, which reduces the size and memory requirements of the model.

GGML, para usarlo con HF transformers (deprecated).

GGUF, mejora de GGML
