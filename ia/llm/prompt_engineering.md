<https://www.promptingguide.ai/models>
<https://learnprompting.org/>
<https://github.com/pinecone-io/examples/blob/master/generation/prompt-engineering.ipynb>
<https://www.pinecone.io/learn/langchain-prompt-templates/>
<https://news.ycombinator.com/item?id=36197291>

Colleciones de prompts:
<https://docs.anthropic.com/en/prompt-library/library>
<https://smith.langchain.com/hub>

Intructions (ej.: "contesta a la pregunta usando el contexto siguiente. Di "no se" en caso de no saber la respuesta")
External information (informaci√≥n que queremos pasar al modelo)
User input (pregunta del usuario)
Output indicator (el "pie" que le damos al LLM para que empiece a generar el texto)

# few-shot learning

Pasar unos ejemplos de como queremos que se comporte el modelo y luego ya pasarle lo que queremos que genere.

Ejemplo:
<https://www.pinecone.io/learn/langchain-prompt-templates/#:~:text=we%20can%20give%20it%20a%20few%20examples>
