http://spark.incubator.apache.org/

Apache Spark is an open source cluster computing system that aims to make data analytics fast — both fast to run and fast to write.

To run programs faster, Spark offers a general execution model that can optimize arbitrary operator graphs, and supports in-memory computing, which lets it query data faster than disk-based engines like Hadoop.

To make programming faster, Spark provides clean, concise APIs in Scala, Java and Python. You can also use Spark interactively from the Scala and Python shells to rapidly query big datasets.


In-memory framework for interactive and iterative computations
  Resilient Distributed Dataset (RDD): fault-tolerance, in-memory storage abstraction

Scala interface, Java and Python APIs



Spark Streaming [Alpha Release] 
  Large scale streaming computation 
  Ensure exactly one semantics 
  Integrated with Spark -> unifies batch, interactive, and streaming computations! 

